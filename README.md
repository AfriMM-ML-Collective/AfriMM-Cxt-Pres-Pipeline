## AFRICAPTION


[![arXiv](https://img.shields.io/badge/arXiv-2510.17405-red)](https://arxiv.org/abs/2510.17405)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![Hugging Face Dataset](https://img.shields.io/badge/HuggingFace-AfriMM%2FAfriMMD-blue)](https://huggingface.co/datasets/AfriMM/AfriMMD)

### ğŸ“‹ Overview

This repository presents the AfriCaption pipeline, a robust system designed to enhance data quality and ensure continuous improvement in African NLP through advanced translation and evaluation mechanisms. It addresses the critical need for high-quality data in African NLP, where existing machine translation models often exhibit inconsistent performance across languages.

### ğŸ”„ Pipeline

<p align="center">
  <img src="external_assets/pipeline_shot.png" alt="Context Preserving Pipeline overview" width="820" />
</p>


### ğŸ“ Project Structure

```
Cxt-pres-pipeline/
â”œâ”€â”€ africaption/          # Main package module
â”‚   â”œâ”€â”€ __init__.py      # Package initialization and exports
â”‚   â”œâ”€â”€ config.py        # Configuration constants and baseline definitions
â”‚   â”œâ”€â”€ translators.py   # Translation adapter classes (Marian, NLLB-like)
â”‚   â”œâ”€â”€ scorer.py        # Semantic similarity scoring (LaBSE)
â”‚   â”œâ”€â”€ dataset.py       # Dataset loading and utilities
â”‚   â”œâ”€â”€ adapter_loader.py # YAML configuration loader
â”‚   â”œâ”€â”€ pipeline.py      # Main processing pipeline
â”‚   â””â”€â”€ cli.py           # Command-line interface
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ models_multilingual.yaml
â”‚   â””â”€â”€ models_marian.yaml
â”œâ”€â”€ outputs/             # Generated output files
â”œâ”€â”€ main.py              # Entry point script
â”œâ”€â”€ test.py              # Quick test script (5 samples)
â”œâ”€â”€ run.py               # Full dataset processing script
â””â”€â”€ README.md
```

### ğŸš€ Quick Start

**ğŸ§ª Test with 5 samples:**
```bash
python test.py
```

**â–¶ï¸ Process entire dataset:**
```bash
python run.py
```

**âš™ï¸ Custom usage:**
```bash
python main.py --test                                    # Test mode
python main.py --models-yaml config/models.yaml         # Custom config
python main.py --out-dir custom_outputs                 # Custom output
```

### ğŸ’¡ Usage

The pipeline automatically:
- Detects model configuration files (`config/models_multilingual.yaml` by default)
- Identifies language overlaps between dataset and models
- Compares translation quality via semantic similarity (LaBSE)
- Retains higher-scoring translations (old or new)
- Generates outputs in JSONL and Parquet formats with audit trails

### âš™ï¸ Configuration

Model configurations are defined in YAML files under `config/`:

**Multilingual NLLB-like model:**
```yaml
type: "nllb_like"
model: "facebook/nllb-200-distilled-600M"
lang_tokens:
  afr: "afr_Latn"
  amh: "amh_Ethi"
  ...
```

**Per-language Marian models:**
```yaml
models:
  afr: "Helsinki-NLP/opus-mt-en-af"
  amh: "Helsinki-NLP/opus-mt-en-am"
  ...
```

### ğŸ“ Output

The pipeline generates:
- `outputs/afrimmd_updated.jsonl` - JSONL format with audit trail
- `outputs/afrimmd_updated.parquet` - Parquet format for analysis

Each record includes an `_audit` field with translation quality scores and retention decisions.

### ğŸ“š Citations

If you use this pipeline or dataset, please cite:

```bibtex
@misc{oduwole2025africaptionestablishingnewparadigm,
  title={AFRICAPTION: Establishing a New Paradigm for Image Captioning in African Languages}, 
  author={Mardiyyah Oduwole and Prince Mireku and Fatimo Adebanjo and Oluwatosin Olajide and Mahi Aminu Aliyu and Jekaterina Novikova},
  year={2025},
  eprint={2510.17405},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2510.17405}
}
```
